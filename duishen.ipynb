{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pandas as pd\n",
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "LTL7PxqJmnN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator:\n",
        "    def __init__(self, model_name=\"ai-forever/mGPT-1.3B-kirgiz\"):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def generate(self, prompt, max_length=50, temperature=0.9):\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_length,\n",
        "            temperature=temperature,\n",
        "            do_sample=True\n",
        "        )\n",
        "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "wyAu15dSmtq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    @staticmethod\n",
        "    def load_and_split_data(file_path, num_words=8):\n",
        "        df = pd.read_csv(file_path, header=None, names=[\"full_text\"])\n",
        "        def split_text(text):\n",
        "            words = str(text).split()\n",
        "            prompt = \" \".join(words[:num_words])\n",
        "            completion = \" \".join(words[num_words:]) if len(words) > num_words else \"\"\n",
        "            return pd.Series([prompt, completion])\n",
        "\n",
        "        df[[\"prompt\", \"completion\"]] = df[\"full_text\"].apply(split_text)\n",
        "        return Dataset.from_pandas(df[[\"prompt\", \"completion\"]])"
      ],
      "metadata": {
        "id": "fomd0F1etSk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = TextGenerator()\n",
        "preprocessor = DataPreprocessor()"
      ],
      "metadata": {
        "id": "7bU0SEbEtnDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = preprocessor.load_and_split_data(\"all_texts.txt\")"
      ],
      "metadata": {
        "id": "UFeCzVqv3w_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Бүгүнкү аба ырайы\"\n",
        "output = generator.generate(prompt, max_length=500)\n",
        "print(\"\\nOutput:\", output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMTnT68r3ws4",
        "outputId": "b0ed8539-5fd9-46ce-c4e1-99235ba839b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Output: Бүгүнкү аба ырайына жараша Ош шаарында абал кандай, шаардыктардын саны канча?\n",
            "22/04 12:50 774 0\n",
            "23/04 19:02 1150 0\n",
            "21/04 12:31 1011 0\n",
            "\n",
            "\n",
            "\n",
            "“Эл аралык” сыйлык тапшыруу аземи өттү\n",
            "16:14 17.01.2018 (жаңыланган 16:29 18.01.2018)\n",
            "Бүгүн, 17-январда Кыргызстандын президенти Сооронбай Жээнбеков Казакстан Республикасынын президенти Нурсултан Назарбаев менен учурашып, “Эл аралык сыйлык тапшыруу аземи” Россия Федерациясынын президенти Владимир Путин менен болгон жолугушуусунда, Россия Федерациясынын президенти Сооронбай Жээнбековду Казакстан Республикасынын Президентинин тушунда... →\n",
            "Бүгүн, 17-январда Кыргызстандын президенти Сооронбай Жээнбеков Казакстан Республикасынын президенти Нурсултан Назарбаев менен учурашып, “Эл аралык сыйлык тапшыруу аземи” Россия Федерациясынын президенти Владимир Путин менен болгон жолугушуусунда, Россия Федерациясынын президенти Сооронбай Жээнбековду Казакстан Республикасынын Президентинин тушунда өз ыктыяры менен “Ак тилек” эл аралык марафонуна... →\n",
            "Кыргызстандын президенти Сооронбай Жээнбеков Казакстан Республикасынын Президенти Нурсултан Назарбаев менен жолугушту\n",
            "Бүгүн, 17-январда Кы\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(self, save_dir):\n",
        "    self.model.save_pretrained(save_dir)\n",
        "    self.tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "@classmethod\n",
        "def from_saved(cls, save_dir):\n",
        "    return cls(save_dir)"
      ],
      "metadata": {
        "id": "bRnT7fhuqU4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WfILCmF7VKfg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}